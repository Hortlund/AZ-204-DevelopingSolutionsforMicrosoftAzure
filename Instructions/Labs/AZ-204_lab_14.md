---
lab:
    az204Title: 'Lab 14: Develop apps for Azure storage'
    az204Module: 'Learning Path 12: Implement caching for solutions'
---

# Lab 14: Develop apps for Azure storage

## Microsoft Azure user interface

Given the dynamic nature of Microsoft cloud tools, you might experience Azure UI changes that occur after the development of this training content. As a result, the lab instructions and lab steps might not align correctly.

Microsoft updates this training course when the community alerts us to needed changes. However, cloud updates occur frequently, so you might encounter UI changes before this training content updates. **If this occurs, adapt to the changes, and then work through them in the labs as needed.**

## Instructions

### Before you start

#### Sign in to the lab environment

Sign in to your Windows 10 virtual machine (VM) by using the following credentials:

- Username: `Admin`
- Password: `Pa55w.rd`

> **Note**: Your instructor will provide instructions to connect to the virtual lab environment.

#### Review the installed applications

Find the taskbar on your Windows 10 desktop. The taskbar contains the icon for the application that you'll use in this lab:

- Microsoft Edge

## Lab Scenario

In this lab, you will implement a storage account, a blob container for the images, and secure the storage account using shared access signatures for the customer to access and download their images.

You will also implement an Azure Cosmos DB instance to store customer-related data for billing information. The connection string to the Azure Cosmos DB will be secured using Azure Key Vault. The Azure Functions will use this information to securely access Azure Cosmos DB.

Since there may be multiple orders arriving simultaneously, you will also make use of message queuing to store the order and job information before it is written to the database.



## Architecture diagram

![Architecture diagram depicting a user enhancing a web application by using the Azure Content Delivery Network](./media/Lab14-Diagram.png)

### Exercise 1: Implement Azure Storage solutions for your application

#### Task 1: Create an Azure Storage resource

1. Log in to the Azure portal at `https://portal.azure.com/`.

1. In the Azure portal, use the **Search resources, services, and docs** text box to search for **Storage Accounts**, and then in the list of results, select **Storage Accounts**.

1. On the **Storage accounts** blade, select **+ Create**.

1. On the **Create a storage account** blade, on the **Basics** tab, perform the following actions, and then select **Review**:

    | Setting | Action |
    | -- | -- |
    | **Subscription** drop-down list | Retain the default value |
    | **Resource group** section | Select **Create new**, enter **ManagedPlatform**, and then select **OK** |
    | **Storage account name** text box | Enter **webstor**_[yourname]_ | 
    | **Region** drop-down list | Select **(US) East US** |
    | **Performance** section | Select the **Standard** option |
    | **Redundancy** drop-down list | Select **Locally-redundant storage (LRS)** |
    
1. On the **Review** tab, review the options that you selected during the previous steps and then select **Create**.

    > **Note**: Wait for the creation task to complete before you proceed with this lab.

1. On the **Overview** blade, select the **Go to resource** button to navigate to the blade of the newly created storage account.

1. On the **Storage account** blade, in the **Security + networking** section, select **Access keys**.

1. On the **Access keys** blade, select **Show keys**.

1. Review any one of the keys, and then copy the value of either of the **Connection string** boxes to the clipboard.

    > **Note**: It doesn't matter which connection string you choose. They are interchangeable.

1. Open Notepad, and then paste the copied connection string value to Notepad. You'll use this value later in this lab.
      

#### Task 2: Create Blob storage solution

1. On the **Storage Account** blade, in the **Data storage** section, select the **Containers** link.

1. On the **Containers** blade, select **+ Container**.

1. In the **New container** window, perform the following actions:

    | Setting  | Action |
    | -- | -- |
    | **Name** text box | Enter **containername** |
    | **Public access level** list | Select **Blob (anonymous read access for blobs only)**, and then select **Create** |
    
   You can now use this Blob container to store and manage unstructured data such as images, videos, documents, and log files.    

1. On the **Containers** blade, select the newly created **containername** container.

1. On the **containername** blade, select **Upload**.

1. In the **Upload blob** window, perform the following actions:

    | Setting | Action |
    | -- | -- |
    | **Files** section | Select **Browse for files** or use the drag and drop feature |
    | **File Explorer** window | Browse to **Allfiles (F):\\Allfiles\\Labs\\14\\Starter\\Images**, select the **filename** file, and then select **Open** |
    | **Overwrite if files already exist** check box | Ensure that the check box is selected, and then select **Upload** |

    > **Note**: Wait for the blob to upload before you continue with this lab.

#### Task 3: Create an Azure file share

1. On the **Storage Account** blade, in the **Data storage** section, select the **File shares** link.

1. On the **File shares** blade, select **+ File share**.

1. In the **File shares** window, perform the following actions:

    | Setting | Action |
    | -- | -- |
    | **Name** text box | Enter **filesharename** |
    | **Tier** drop-down list | Select **Transaction optimized**, and then select **Create** |

You can now use this file share to store and share files across multiple virtual machines or applications.

#### Task 4: Secure Azure Storage by using Key Vault for the storage key

1. Log in to the Azure portal (https://portal.azure.com/).
Create a new Key Vault resource in the same region as your storage account.
In the Key Vault resource, click on the "Access policies" option from the left-hand menu.
Click on the "+ Add Access Policy" button.
Select the "Secret Management" option from the list of available permissions.
Choose the appropriate options for the "Select principal" and "Secret permissions" sections, depending on your requirements.
Click on the "Add" button to add the access policy.
In the Key Vault resource, click on the "Secrets" option from the left-hand menu.
Click on the "+ Generate/Import" button to create a new secret.
Enter a name for the secret and choose the "Manual" option for the "Upload options" section.
Enter the storage account key as the secret value.
Click on the "Create" button to create the new secret.
In the Azure Storage account, click on the "Access keys" option from the left-hand menu.
Click on the "Regenerate key" button to generate a new key.
Choose the "Use a key from Key Vault" option for the new key.
Select the Key Vault resource and secret that you created earlier.
Click on the "Save" button to save the new key.
Update your application or service to use the new storage account key.

By using Key Vault to store and manage your Azure Storage keys, you can ensure that your keys are securely stored and managed, and you can easily rotate your keys as needed for improved security.

#### Task 5: Secure Azure Storage using shared access signature

1. Log in to the Azure portal (https://portal.azure.com/).
Navigate to the Azure Storage account that you want to secure.
Click on the "Shared access signature" option from the left-hand menu.
Choose the appropriate options for the "Allowed services", "Allowed resource types", "Allowed permissions", and "Start time/Expiry time" sections, depending on your requirements.
Click on the "Generate SAS and connection string" button to generate the shared access signature and connection string.
Copy the generated connection string to your clipboard.
Update your application or service to use the new connection string for accessing the Azure Storage account.

By using shared access signature, you can control the level of access that different users or applications have to your Azure Storage account. You can specify the allowed services, resource types, and permissions for each shared access signature, and you can set the start time and expiry time to control the duration of each shared access signature.


#### Review 

 From this exercise, the students learned how to implement Azure Storage solutions for their applications. Specifically, they learned how to create an Azure Storage resource, create a Blob storage solution, create an Azure file share, secure Azure Storage by using Key Vault for the storage key, and secure Azure Storage using shared access signature.

### Exercise 2: Implement Azure Cosmos DB solutions

#### Task 1: Create an Azure Cosmos DB instance

1. In the Azure portal, use the **Search resources, services, and docs** text box to search for **Azure Cosmos DB** and then in the list of results, select **Azure Cosmos DB**.

1. On the **Azure Cosmos DB** blade, select **+ Create**.

1. On the **Select API option** blade, select **Create** in the **Azure Cosmos DB for NoSQL** box.

1. On the **Basics** tab of the **Create Azure Cosmos DB Account - Azure Cosmos DB for NoSQL** page, perform the following actions, and then select **Review + Create**:

    | Setting | Action |
    | -- | -- |
    | **Subscription** list | Retain defaults |
    | **Resource group** section  | Select **Create new** |
    | **Name** text box | Enter **Polyglotdata** and select **OK** |
    | **AccountName** text box | Enter **polycosmos**_[yourname]_ |
    | **Location** drop-down list | Select an Azure region that is closest to the location of your lab computer and where you can create a Cosmos DB account |
    | **Capacity mode** section | Select **Serverless** |
    
2. On the **Review + Create** tab of the **Create Azure Cosmos DB Account - Azure Cosmos DB for NoSQL** page, review the options that you selected during the previous steps. 

3. Select **Create** to create the Azure Cosmos DB account by using your specified configuration.

    > **Note**: Wait for the creation task to complete before you move forward with this lab.

4. Select **Go to resource**.

5. On the **Azure Cosmos DB account** blade, find the **Settings** section, and then select the **Keys** link.

6. In the **Keys** pane, on the **Read-write Keys** tab, record the values of the **URI**, **PRIMARY KEY**, and **PRIMARY CONNECTION STRING** text boxes. You'll use these values later in this lab.



Navigate to the Azure portal and log in to your account.
Click on the "Create a resource" button on the top left-hand side of the screen.
In the search bar, type "Azure Cosmos DB" and select the option from the dropdown menu.
Click on the "Create" button to begin setting up your Cosmos DB instance.
In the "Basics" tab, choose the subscription you want to use, create a new resource group or select an existing one, and give your Cosmos DB instance a unique name.
Choose the API you want to use - for example, SQL, MongoDB, Cassandra, etc.
Choose the location where you want your Cosmos DB instance to be hosted.
Under the "Networking" tab, select the connectivity method you want to use (public endpoint or private endpoint) and configure the firewall settings as needed.
Under the "Advanced" tab, you can configure additional settings such as enabling automatic failover, enabling geo-replication, and setting up virtual network service endpoints.
Review the settings you have chosen and click on the "Create" button to create your Azure Cosmos DB instance.

Congratulations, you have successfully completed Task 1 and created an Azure Cosmos DB instance!



#### Task 2: Secure the Azure Cosmos DB connection string in Key Vault

Navigate to the Azure portal and sign in to your account.
Click on "Create a resource" button and select "Key Vault" from the "Security + Identity" category.
Fill in the required fields for creating the Key Vault instance, such as the subscription, resource group, and name.
Choose the pricing tier that suits your needs and click on "Review + create".
Review the settings and click on "Create" to create the Key Vault instance.
Once the Key Vault instance is created, navigate to its dashboard.
Click on "Secrets" in the left-hand menu and then click on "Generate/Import".
Fill in the required fields for creating a new secret, such as the name and value (the connection string for your Azure Cosmos DB instance).
Click on "Create" to create the new secret.
Navigate to your Azure Cosmos DB instance and open its settings.
Click on "Connection String" in the left-hand menu and copy the primary connection string.
Navigate back to your Key Vault instance and click on the secret you just created.
Click on "Versions" in the left-hand menu and then click on "Set Secret".
Paste the primary connection string into the "Value" field and click on "Create".
Your Azure Cosmos DB connection string is now securely stored in Key Vault and can be accessed by your Azure Functions.


#### Review 


### Exercise 3: Implement Event Hub processing and message queueing (Use Event Hub and/or Event Grid)

#### Task 1: Implement a message queue for writing and reading customer transaction information

Navigate to the Azure portal and sign in to your account.
Click on "Create a resource" button and select "Storage account" from the "Storage" category.
Fill in the required fields for creating the storage account, such as the subscription, resource group, and name.
Choose the pricing tier that suits your needs and click on "Review + create".
Review the settings and click on "Create" to create the storage account.
Once the storage account is created, navigate to its dashboard.
Click on "Containers" in the left-hand menu and then click on "Create container".
Fill in the required fields for creating a new container, such as the name and access level (set to "Private" for security).
Click on "Create" to create the new container.
Navigate to the "Access keys" section in the left-hand menu and copy one of the connection strings (either the primary or secondary).
Navigate to the Azure portal home page and click on "Create a resource" button and select "Service Bus" from the "Integration" category.
Fill in the required fields for creating the Service Bus instance, such as the subscription, resource group, and name.
Choose the pricing tier that suits your needs and click on "Review + create".
Review the settings and click on "Create" to create the Service Bus instance.
Once the Service Bus instance is created, navigate to its dashboard.
Click on "Queues" in the left-hand menu and then click on "Create queue".
Fill in the required fields for creating a new queue, such as the name and access level (set to "Private" for security).
Click on "Create" to create the new queue.
Navigate to your Azure Function that writes the customer transaction information to Azure Cosmos DB.
In the "Integrate" tab, add a new input binding for Service Bus.
Fill in the required fields for the input binding, such as the connection string (from the Service Bus instance), the queue name, and the message parameter name.
Click on "Save" to save the input binding.
In your Azure Function code, write code to send a message to the Service Bus queue whenever a customer transaction is created.
Navigate to your Azure Function that generates billing information for the invoicing system.
In the "Integrate" tab, add a new input binding for Service Bus.
Fill in the required fields for the input binding, such as the connection string (from the Service Bus instance), the queue name, and the message parameter name.
Click on "Save" to save the input binding.
In your Azure Function code, write code to read messages from the Service Bus queue and generate billing information for each customer transaction.

#### Task 2: Create an Event Hub to monitor HTTP requests for uploaded images

Navigate to the Azure portal and sign in to your account.
Click on "Create a resource" button and select "Event Hubs" from the "Integration" category.
Fill in the required fields for creating the Event Hub, such as the subscription, resource group, and name.
Choose the pricing tier that suits your needs and click on "Review + create".
Review the settings and click on "Create" to create the Event Hub.
Once the Event Hub is created, navigate to its dashboard.
Click on "Shared access policies" in the left-hand menu and then click on "Add".
Fill in the required fields for creating a new shared access policy, such as the name and permissions (set to "Send" and "Listen" for now).
Click on "Create" to create the new shared access policy.
Navigate to the "Overview" tab and copy the connection string for the Event Hub namespace.
In your Azure Function that processes HTTP requests for uploaded images, add a new output binding for Event Hub.
Fill in the required fields for the output binding, such as the connection string (from the Event Hub namespace), the name of the Event Hub, and the message parameter name.
Click on "Save" to save the output binding.
In your Azure Function code, write code to send a message to the Event Hub whenever a customer uploads an image for processing.
You can now monitor HTTP requests for uploaded images in real-time by reading messages from the Event Hub.


#### Task 3: Create and Event Hub to trigger customer invoicing based on a time trigger

Navigate to the Azure portal and sign in to your account.
Click on "Create a resource" button and select "Event Hubs" from the "Integration" category.
Fill in the required fields for creating the Event Hub, such as the subscription, resource group, and name.
Choose the pricing tier that suits your needs and click on "Review + create".
Review the settings and click on "Create" to create the Event Hub.
Once the Event Hub is created, navigate to its dashboard.
Click on "Shared access policies" in the left-hand menu and then click on "Add".
Fill in the required fields for creating a new shared access policy, such as the name and permissions (set to "Send" and "Listen" for now).
Click on "Create" to create the new shared access policy.
Navigate to the "Overview" tab and copy the connection string for the Event Hub namespace.
Create a new Azure Function that will be triggered based on a time trigger.
In the "Integrate" tab, add a new output binding for Event Hub.
Fill in the required fields for the output binding, such as the connection string (from the Event Hub namespace), the name of the Event Hub, and the message parameter name.
Click on "Save" to save the output binding.
In your Azure Function code, write code to send a message to the Event Hub that contains the customer information and job details for all completed image processing jobs.
The Event Hub will trigger the Azure Function that generates billing information for the invoicing system based on the time trigger.
In the "Integrate" tab of this Azure Function, add a new input binding for Event Hub.
Fill in the required fields for the input binding, such as the connection string (from the Event Hub namespace), the name of the Event Hub, and the message parameter name.
Click on "Save" to save the input binding.
In your Azure Function code, write code to read messages from the Event Hub and generate billing information for each completed image processing job.

### Task 4: Create a .NET application to upload images to the blob storage

Open Visual Studio and create a new project using the "ASP.NET Web Application (.NET Framework)" template.
Choose the "MVC" project type and select "No Authentication" for now.
Click on "Create" to create the project.
Right-click on the project in the Solution Explorer and select "Manage NuGet Packages".
Install the "WindowsAzure.Storage" NuGet package.
In the "web.config" file, add the following configuration settings for the connection string to the Azure Storage Account:

```csharp
<configuration>  
  <connectionStrings>  
    <add name="StorageConnectionString" connectionString="DefaultEndpointsProtocol=https;AccountName=[your_account_name];AccountKey=[your_account_key];EndpointSuffix=core.windows.net" />  
  </connectionStrings>  
</configuration>  
 ```
7. Create a new controller by right-clicking on the "Controllers" folder in the Solution Explorer and selecting "Add" -> "Controller".

Choose the "MVC 5 Controller - Empty" template and name the controller "ImageController".
In the "ImageController.cs" file, add the following code:

```csharp
using Microsoft.WindowsAzure.Storage;  
using Microsoft.WindowsAzure.Storage.Blob;  
using System.IO;  
using System.Threading.Tasks;  
using System.Web;  
using System.Web.Mvc;  
  
namespace YourProject.Controllers  
{  
    public class ImageController : Controller  
    {  
        private CloudBlobContainer GetCloudBlobContainer()  
        {  
            // Retrieve the connection string for use with the application. The storage account name and key are stored  
            // in the connection string.  
            string connectionString = System.Configuration.ConfigurationManager.ConnectionStrings["StorageConnectionString"].ConnectionString;  
  
            // Retrieve storage account from connection string.  
            CloudStorageAccount storageAccount = CloudStorageAccount.Parse(connectionString);  
  
            // Create a blob client for interacting with the blob service.  
            CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();  
  
            // Retrieve reference to a previously created container.  
            CloudBlobContainer container = blobClient.GetContainerReference("images");  
  
            // Create the container if it doesn't already exist.  
            container.CreateIfNotExists();  
  
            // Enable public access to the container.  
            container.SetPermissions(  
                new BlobContainerPermissions  
                {  
                    PublicAccess = BlobContainerPublicAccessType.Blob  
                });  
  
            return container;  
        }  
  
        [HttpPost]  
        public async Task<ActionResult> Upload(HttpPostedFileBase file)  
        {  
            if (file != null && file.ContentLength > 0)  
            {  
                // Get the container reference.  
                CloudBlobContainer container = GetCloudBlobContainer();  
  
                // Retrieve reference to a blob named "myblob".  
                CloudBlockBlob blockBlob = container.GetBlockBlobReference(file.FileName);  
  
                // Upload the file to blob storage.  
                using (var fileStream = file.InputStream)  
                {  
                    await blockBlob.UploadFromStreamAsync(fileStream);  
                }  
            }  
  
            return RedirectToAction("Index", "Home");  
        }  
    }  
}  
 ```

10. In the "Views" folder, create a new folder called "Image" and then add a new view by right-clicking on the "Image" folder and selecting "Add" -> "View".

Name the view "Upload" and add the following code:

```csharp
@{  
    ViewBag.Title = "Upload Image";  
}  
  
<h2>@ViewBag.Title</h2>  
  
@using (Html.BeginForm("Upload", "Image", FormMethod.Post, new { enctype = "multipart/form-data" }))  
{  
    <input type="file" name="file" />  
    <br />  
    <input type="submit" value="Upload" />  
}  
```

12. Run the application and navigate to the "Image/Upload" view to upload an image file to the "images" container in the Azure Storage Account.


#### Review 


### Exercise 4: Implement Azure Functions to process messages

#### Task 1: Create an Azure function that reads customer data from the message queue

Open the Azure portal and navigate to the Function App that you want to use.
Click on the "Functions" menu item and then click on the "+ New Function" button.
Choose "Azure Queue Storage trigger" as the template for the new function.
Fill in the required fields, such as the name of the function, the name of the storage account, and the name of the queue.
Choose the "C#" language and click on "Create".
In the "function.json" file, modify the "connection" property to specify the name of the Azure Storage Account connection string that you want to use.
In the "run.csx" file, write the code to read the customer data from the message queue. Here's an example:
#r "Microsoft.WindowsAzure.Storage"  

```csharp  
using System;  
using Microsoft.WindowsAzure.Storage;  
using Microsoft.WindowsAzure.Storage.Queue;  
  
public static void Run(CloudQueueMessage myQueueItem, TraceWriter log)  
{  
    log.Info($"C# Queue trigger function processed: {myQueueItem.AsString}");  
  
    // Retrieve the customer data from the message body.  
    string[] customerInfo = myQueueItem.AsString.Split(',');  
  
    string customerId = customerInfo[0];  
    string customerName = customerInfo[1];  
    string customerEmail = customerInfo[2];  
  
    // Do something with the customer data, such as store it in a database or send an email.  
}  
```

8. Save the changes to the "run.csx" file.

9. Test the function by adding a message to the specified queue in the Azure Storage Account. The message should contain the customer data in the format: "customerId,customerName,customerEmail". The function should be triggered automatically and the customer data should be processed according to the code in the "run.csx" file.

#### Task 2: Create an Azure function that writes data from the message queue to the Azure Cosmos DB

Open the Azure portal and navigate to the Function App that you want to use.
Click on the "Functions" menu item and then click on the "+ New Function" button.
Choose "Azure Queue Storage trigger" as the template for the new function.
Fill in the required fields, such as the name of the function, the name of the storage account, and the name of the queue.
Choose the "C#" language and click on "Create".
In the "function.json" file, modify the "connection" property to specify the name of the Azure Storage Account connection string that you want to use.
In the "run.csx" file, write the code to read the customer data from the message queue and write it to the Azure Cosmos DB. Here's an example:
#r "Microsoft.Azure.Documents.Client"  
#r "Microsoft.Azure.Documents.Linq"  

```csharp  
using System;  
using System.Linq;  
using Microsoft.Azure.Documents;  
using Microsoft.Azure.Documents.Client;  
using Microsoft.Azure.Documents.Linq;  
using Microsoft.WindowsAzure.Storage;  
using Microsoft.WindowsAzure.Storage.Queue;  
  
public static void Run(CloudQueueMessage myQueueItem, TraceWriter log)  
{  
    log.Info($"C# Queue trigger function processed: {myQueueItem.AsString}");  
  
    // Retrieve the customer data from the message body.  
    string[] customerInfo = myQueueItem.AsString.Split(',');  
  
    string customerId = customerInfo[0];  
    string customerName = customerInfo[1];  
    string customerEmail = customerInfo[2];  
  
    // Write the customer data to the Azure Cosmos DB.  
    DocumentClient client = new DocumentClient(new Uri("[cosmos_db_endpoint]"), "[cosmos_db_auth_key]");  
    var collectionUri = UriFactory.CreateDocumentCollectionUri("[cosmos_db_database]", "[cosmos_db_collection]");  
  
    var customer = new  
    {  
        id = customerId,  
        name = customerName,  
        email = customerEmail  
    };  
  
    client.CreateDocumentAsync(collectionUri, customer);  
  
    // Do something else with the customer data, such as send an email or log it.  
}  
``` 
8. Replace "[cosmos_db_endpoint]", "[cosmos_db_auth_key]", "[cosmos_db_database]", and "[cosmos_db_collection]" with the appropriate values for your Azure Cosmos DB account.

9. Save the changes to the "run.csx" file.

10. Test the function by adding a message to the specified queue in the Azure Storage Account. The message should contain the customer data in the format: "customerId,customerName,customerEmail". The function should be triggered automatically and the customer data should be written to the specified Azure Cosmos DB collection.


#### Task 3: Create an Azure function that reads data from the invoicing message queue process

Open the Azure portal and navigate to the Function App that you want to use.
Click on the "Functions" menu item and then click on the "+ New Function" button.
Choose "Azure Queue Storage trigger" as the template for the new function.
Fill in the required fields, such as the name of the function, the name of the storage account, and the name of the queue.
Choose the "C#" language and click on "Create".
In the "function.json" file, modify the "connection" property to specify the name of the Azure Storage Account connection string that you want to use.
In the "run.csx" file, write the code to read the invoicing data from the message queue. Here's an example:
#r "Microsoft.WindowsAzure.Storage"  

```csharp  
using System;  
using Microsoft.WindowsAzure.Storage;  
using Microsoft.WindowsAzure.Storage.Queue;  
  
public static void Run(CloudQueueMessage myQueueItem, TraceWriter log)  
{  
    log.Info($"C# Queue trigger function processed: {myQueueItem.AsString}");  
  
    // Retrieve the invoicing data from the message body.  
    string[] invoicingInfo = myQueueItem.AsString.Split(',');  
  
    string customerId = invoicingInfo[0];  
    string jobDetails = invoicingInfo[1];  
  
    // Do something with the invoicing data, such as generate an invoice or log it.  
}  
```
8. Save the changes to the "run.csx" file.

9. Test the function by adding a message to the specified queue in the Azure Storage Account. The message should contain the invoicing data in the format: "customerId,jobDetails". The function should be triggered automatically and the invoicing data should be processed according to the code in the "run.csx" file.


### Task 4: Create an Azure function that sends customer invoice information to a customer via email

Open the Azure portal and navigate to the Function App that you created in Task 2.

Click on the "Functions" option in the left-hand menu, and then click the "+ Add" button to create a new function.

Choose "Event Hub Trigger" as the template for the new function.

In the "New Function" dialog box, enter a name for your function, such as "SendInvoiceEmailFunction".

Under "Event Hub settings", choose the Event Hub that you created in Task 3.

Under "Connection", select "New", and then select "Azure Cosmos DB" from the list of available connections.

Enter the name of the Cosmos DB account that you created in Task 3.

Under "Input", select "OrderQueue" as the queue that your function will read messages from.

Under "Output", select "SendGrid" as the output binding.

Enter the SendGrid API key that you created in Task 2.

In the "Function code" section, replace the default code with the following code:

```csharp
using System;  
using Microsoft.Azure.WebJobs;  
using Microsoft.Extensions.Logging;  
using Newtonsoft.Json;  
using SendGrid;  
using SendGrid.Helpers.Mail;  
  
public static async Task Run(string[] eventHubMessages, ILogger log, [CosmosDB(databaseName: "your-db-name", collectionName: "your-collection-name", ConnectionStringSetting = "CosmosDBConnection")]IAsyncCollector<dynamic> documents, [SendGrid()]IAsyncCollector<SendGridMessage> message)  
{  
    foreach (var message in eventHubMessages)  
    {  
        var order = JsonConvert.DeserializeObject<Order>(message);  
  
        var document = new  
        {  
            id = Guid.NewGuid().ToString(),  
            customerId = order.CustomerId,  
            jobType = order.JobType,  
            jobCost = order.JobCost,  
            processedDate = DateTime.UtcNow  
        };  
  
        await documents.AddAsync(document);  
  
        var emailMessage = new SendGridMessage();  
        emailMessage.SetFrom(new EmailAddress("your-email-address@example.com", "Contoso Image Processing"));  
        emailMessage.AddTo(new EmailAddress(order.CustomerEmail));  
        emailMessage.SetSubject("Your Contoso Image Processing Invoice");  
        emailMessage.AddContent(MimeType.Text, $"Dear {order.CustomerName},\n\nThank you for using Contoso Image Processing. Your invoice for the {order.JobType} job is {order.JobCost:C}.\n\nBest regards,\nContoso Image Processing");  
  
        await message.AddAsync(emailMessage);  
    }  
}  
  
public class Order  
{  
    public string CustomerId { get; set; }  
    public string CustomerName { get; set; }  
    public string CustomerEmail { get; set; }  
    public string JobType { get; set; }  
    public decimal JobCost { get; set; }  
}  
```

Make sure to replace "your-db-name" and "your-collection-name" with the actual names of your Cosmos DB database and collection.

Click on the "Save" button to save your function.

Test your function by sending a message to the "OrderQueue" queue that you created in Task 3. You can do this by using the Azure Storage Explorer or by using the Azure Portal.

Check your email inbox to verify that you received the invoice email.

Congratulations! You have successfully created an Azure function that sends customer invoice information to a customer via email.


#### Review

In this exercise, you updated your web app to use Content Delivery Network to serve multimedia content and to serve the web application itself.